<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>2012-10-18-an_implementation_of_the_fixed-radius_near_neighbor_clustering_algorithm_in_lisp</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="style.css" />
  <html>
  <meta http-equiv="content-type" content="text/html; charset=UTF-8">
  <base href="https://kaygun.github.io/">
  <link rel="stylesheet" type="text/css" href="style.css">


  <head>
  <title>The Kitchen Sink and Other Oddities</title>
  </head>

  <body>
  <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ['\\(','\\)'] ]
    }
  });
  </script>

  <div class="header">
  <h1><a href="https://kaygun.github.io">The Kitchen Sink and Other Oddities</a></h1>
  <p><a href="https://web.itu.edu.tr/kaygun">Atabey Kaygun</a></p>
  </div>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<h1
id="an-implementation-of-the-fixed-radius-near-neighbor-clustering-algorithm-in-lisp">An
implementation of the fixed-radius near neighbor clustering algorithm in
lisp</h1>
<h2 id="descriptionoftheproblemandthealgorithm">Description of the
problem and the algorithm</h2>
<p>The setup is the same as in my <a
href="clean/2012-10-10-an.html">k-means clustering post</a>. I have a
metric space <span class="math inline">\((X,d)\)</span> and a finite
collection of points <span class="math inline">\(D =
{x_1,\ldots,x_N}\)</span> which I would like to write as a union of
disjoint subsets <span class="math display">\[ D = D_1 \sqcup \cdots
\sqcup D_k \]</span> This time, unlike the k-means algorithm, the number
k is not fixed at the beginning. This time we feed the algorithm a
number which I will call <em>cluster diameter</em>.</p>
<p>The diameter of a set of points in a metric space is defined by <span
class="math display">\[
diam© = \sup_{x,y\in C} d(x,y) \]</span> If <span
class="math inline">\(C\)</span> happens to be finite then this is just
the maximumum of all possible distances one can write using pairs of
elements from the set <span class="math inline">\(C\)</span>. I will
need an auxiliary function I will call <code>proximity</code> which is
defined as <span class="math display">\[
\text{proximity}(x,C) = \sup_{y\in C} d(x,y) \]</span></p>
<p>The fixed-radius near neighbor clustering algorithm will form
clusters of points whose diameters are less than or equal to a given
radius.</p>
<p>So, here is our algorithm in pseudo code</p>
<pre><code>Function frnn(D, radius)

1. Pick a point at random, call it p 
2. Let the initial set of clusters be the set
   which contains only the one point cluster {p}.
   That is, let Clusters = { {p} }
3. For every x in D do
   a.  For every C in Clusters calculate the proximity of x to C 
   b.  If promity of x is greater than radius for every C in Clusters 
       then add a new one point cluster {x} to Clusters.
   c.  Otherwise find the cluster C such that proximity(x,C) is 
       minimal and add x to that cluster.

 return Clusters</code></pre>
<h2 id="animplementationinlisp">An implementation in lisp</h2>
<p>Here is my implementation of the algorithm in lisp: I will assume
that data is given as a list of data-points, and that a distance
function called <code>distance</code> is already defined for the data I
have.</p>
<pre><code>(defun range (N) (loop for i from 0 below N collect i))

(defun proximity (x cluster)
     (reduce &#39;max (mapcar (lambda (y) (distance x y)) cluster)))

(defun frnn (data radius)
   (let* ((len (length data))
          (p (car data))
          (copy (cdr data))
          (clusters (list (list p))))
      (dolist (x copy)
                 (let* ((res (mapcar (lambda (C i) (cons (proximity x C) i)) clusters (range len)))
                        (which (if (&gt; (length res) 1) 
                                  (car (sort res (lambda (u v) (&lt; (car u) (car v)))))
                                  (car res))))
                     (if (&lt; (car which) radius)
                        (push x (nth (cdr which) clusters))
                        (push (list x) clusters))))
      clusters))</code></pre>
<p>The implementation I gave above cut some corners: instead of
assigning an initial point <code>p</code> randomly, I took it as the
first element in the dataset. I should have get an element randomly then
<code>copy</code> list should be obtained from <code>data</code> by
deleting the chosen element <code>p</code>.</p>
<p>Let us test this algorithm on the dataset we used to test our <a
href="clean/2012-10-10-an.html">k-means clustering algorithm</a>. I will
copy the code I used there below together with the utility functions I
used to load the data.</p>
<pre><code>(require :cl-ppcre)
NIL


(defun read-data(name)
  (with-open-file (file name)
    (let (line)
        (loop while (setf line (read-line file nil)) collect
             (if (&gt; (length line) 0) 
                (map &#39;vector &#39;read-from-string (ppcre:split #\, line)))))))

(setq data (read-data &quot;iris.csv&quot;))

(defun distance (x y) 
  (reduce &#39;+ (map &#39;list (lambda (i j k) (abs (- i j k))) x y (make-array (1- (length x)) :initial-element 0))))
DISTANCE</code></pre>
<p>Let us chose a point at random, a small sample at random and
calculate the proximity measure to test the code:</p>
<pre><code>(setq NUM (length data))
(setq point (nth (random NUM) data))
(setq sample (loop for i from 1 to 63 collect (nth (random NUM) data)))
(proximity point sample)
7.8999996</code></pre>
<p>Now, since we don’t know how many clusters we are going to get
depending on the radius, we must try few values and see how many
clusters we will get together with the distribution of classes within
each cluster.</p>
<pre><code>(setq clusters (frnn data 5.5))
(length clusters)
3</code></pre>
<p>Let us see the composition of these clusters</p>
<pre><code>(setq report nil)
(setq N (1- (length (car data))))

(dolist (i (range (length clusters)))
   (dolist (x (nth i clusters))
      (if (assoc (cons (aref x N) i) report :test #&#39;equal)
         (incf (cdr (assoc (cons (aref x N) i) report :test #&#39;equal)))
         (push (cons (cons (aref x N) i) 1) report))))
report
(((IRIS-SETOSA . 2) . 50) ((IRIS-VERSICOLOR . 1) . 50)
 ((IRIS-VIRGINICA . 1) . 13) ((IRIS-VIRGINICA . 0) . 37))</code></pre>
<p>The results indicate all of the samples from <em>IRIS VERSICILOR</em>
are clustered together in cluster 0. Similarly samples from <em>IRIS
SETOSA</em> are clustered together in cluster 2. Unfortunately, <em>IRIS
VIRGINICA</em> samples are split between clusters 0 and 1, and if a
sample falls within cluster 1 the odds that it is a <em>IRIS
VERSICOLOR</em> against being a <em>IRIS VIRGINICA</em> is 4 to 1.</p>
<p>Let us try another radius and see the distribution in that case</p>
<pre><code>(setq clusters (frnn data 8.9))

(setq report nil)
(setq N (1- (length (car data))))

(dolist (i (range (length clusters)))
   (dolist (x (nth i clusters))
      (if (assoc (cons (aref x N) i) report :test #&#39;equal)
         (incf (cdr (assoc (cons (aref x N) i) report :test #&#39;equal)))
         (push (cons (cons (aref x N) i) 1) report))))
report
(((IRIS-SETOSA . 1) . 50) ((IRIS-VERSICOLOR . 1) . 50)
 ((IRIS-VIRGINICA . 0) . 50))</code></pre>
<p>We now have only two clusters and <em>IRIS SETOSA</em> and <em>IRIS
VERSICOLOR</em> samples are clumped together while we can distinguish
the samples from <em>IRIS VIRGINICA</em> from the rest of the
samples.</p>
<div id="footer">
<p><span id="timestamp">October 18th, 2012 1:25pm</span></p>
</div>
</body>
</html>
