<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>2015-07-21-hidden_markov_models_via_tropic_matrices</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <link rel="stylesheet" href="style.css" />
  <html>
  <meta http-equiv="content-type" content="text/html; charset=UTF-8">
  <base href="https://kaygun.github.io/">
  <link rel="stylesheet" type="text/css" href="style.css">


  <head>
  <title>The Kitchen Sink and Other Oddities</title>
  </head>

  <body>
  <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ['\\(','\\)'] ]
    }
  });
  </script>

  <div class="header">
  <h1><a href="https://kaygun.github.io">The Kitchen Sink and Other Oddities</a></h1>
  <p><a href="https://web.itu.edu.tr/kaygun">Atabey Kaygun</a></p>
  </div>

  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<h1 id="hidden-markov-models-via-tropic-matrices">Hidden Markov Models
via Tropic Matrices</h1>
<p>I covered some of the material in <a
href="clean/2015-06-28-an_implementation_of_the_viterbi_algorithm_in_common_lisp.html">my
previous post</a>, but let me repeat it anyway.</p>
<h2 id="description-of-the-problem">Description of the problem</h2>
<p>We have an ordered sequence of observations <span
class="math inline"><em>x</em><sub>1</sub>, <em>x</em><sub>2</sub>, …, <em>x</em><sub><em>N</em></sub></span>
where each observation is labeled from a finite set of classes <span
class="math inline"><em>Y</em></span>. The probability that an
observation <span class="math inline"><em>x</em></span> is labeled as
<span class="math inline"><em>y</em> ∈ <em>Y</em></span> is given by
<span class="math inline"><em>p</em>(<em>y</em>∥<em>x</em>)</span>. We
assume that we know the probability distributions for the observations
<span class="math inline"><em>p</em>(<em>x</em>)</span> and classes
<span class="math inline"><em>p</em>(<em>y</em>)</span>, and the
probability <span
class="math inline"><em>p</em>(<em>x</em>∥<em>y</em>)</span> of seeing
the observation <span class="math inline"><em>x</em></span> under the
label <span class="math inline"><em>y</em></span>. Assume also that we
have transition probabilities <span
class="math inline"><em>p</em>(<em>y</em>′∥<em>y</em>)</span> telling us
the probability of seeing class label <span
class="math inline"><em>y</em>′ ∈ <em>Y</em></span> right after
observing <span class="math inline"><em>y</em> ∈ <em>Y</em></span>.</p>
<p>Our task is to find the labeling scheme <span
class="math inline">ℓ: {<em>x</em><sub>1</sub>, …, <em>x</em><sub><em>N</em></sub>} → <em>Y</em></span>
of the observations with the maximum likelihood. In other words, we need
to maximize <span class="math display">$$ \pi(\ell) =
\prod_{i=1}^N p(\ell(x_i)\|x_i)p(\ell(x_{i+1})\|\ell(x_i)) $$</span> We
set <span
class="math inline"><em>p</em>(ℓ(<em>x</em><sub><em>N</em> + 1</sub>)∥ℓ(<em>x</em><sub><em>N</em></sub>)) = 1</span>
to make the product meaningful.</p>
<h2 id="a-reduction">A reduction</h2>
<p>Taking the logarithms and expanding we get <span
class="math display">$$ \log\pi(\ell) =
\sum_{i=1}^N \log p(\ell(x_i)\| x_i) + \sum_{i=1}^{N-1} \log
p(\ell(x_{i+1})\|\ell(x_i)) $$</span> which then can be simplified as
<span class="math display">$$
= \sum_{i=1}^N \log p(\ell(x_{i+1})\|\ell(x_i)) + \sum_{i=1}^N
\log p(x_i\|\ell(x_i)) + \log p(\ell(x_i)) - \log p(x_i) $$</span>
Notice that we can drop <span
class="math inline">log <em>p</em>(<em>x</em><sub><em>i</em></sub>)</span>
terms since they do not depend on <span class="math inline">ℓ</span>.
Since logarithms of probabilities lie in <span
class="math inline">$(-\infty,0\]$</span>, we need to minimize the
quantity below: <span class="math display">$$
-\log\pi(\ell) \sim \tau(\ell) := \sum_{i=1}^N -\log
p(\ell(x_{i+1})\|\ell(x_i)) + \sum_{i=1}^N -\log
p(x_i\|\ell(x_i)) + \sum_{i=1}^N -\log p(\ell(x_i)) $$</span> Let us
rearrange the terms a bit: <span class="math display">$$ \tau(\ell) = -
\sum_{i=1}^N \log
p(x_i\|\ell(x_i)) + \log p(\ell(x_i)) + \log
p(\ell(x_i)\|\ell(x_{i-1})) $$</span> by letting <span
class="math inline"><em>p</em>(ℓ(<em>x</em><sub>1</sub>)∥ℓ(<em>x</em><sub>0</sub>)) = 1</span>
in the equation.</p>
<h2 id="tropic-semiring">Tropic semiring</h2>
<p>We consider the set of non-negative real numbers <span
class="math inline">$\mathbb{R}_+ := \[0,\infty)$</span> together with
the operations <span class="math inline">min </span> (which we denote as
<span
class="math inline">min (<em>x</em>,<em>y</em>) = <em>x</em> ∧ <em>y</em></span>)
and ordinary product. Notice that <span
class="math display"><em>x</em> + (<em>y</em>∧<em>z</em>) = (<em>x</em>+<em>y</em>) ∧ (<em>x</em>+<em>z</em>)</span>
However, <span class="math inline">∧</span> does not have a unit and
<span
class="math inline">0 ∧ <em>x</em> = <em>x</em> ∧ 0 = 0</span>.</p>
<p>One can form matrices in the tropic semi-rng. Assume we have two such
tropic matrices <span
class="math inline"><em>A</em><sub><em>n</em> × <em>m</em></sub> = (<em>a</em><sub><em>i</em><em>j</em></sub>)</span>
and <span
class="math inline"><em>B</em><sub><em>m</em> × ℓ</sub> = (<em>b</em><sub><em>i</em><em>j</em></sub>)</span>
then the product <span
class="math inline"><em>C</em><sub><em>n</em> × ℓ</sub> = <em>A</em> * <em>B</em></span>
has the entries <span class="math display">$$ c_{ij} = \bigwedge_{k=1}^m
(a_{ik} + b_{kj}) $$</span></p>
<h2 id="re-imagining-our-problem-in-tropic-terms">Re-imagining our
problem in tropic terms</h2>
<p>Let us define matrices <span
class="math inline"><em>ω</em><sub><em>i</em></sub></span> for <span
class="math inline"><em>i</em> = 1, …, <em>n</em></span> as <span
class="math display"><em>ω</em><sub><em>j</em><em>k</em></sub>(<em>i</em>) =  − log <em>p</em>(<em>x</em><sub><em>i</em></sub>∥<em>y</em><sub><em>j</em></sub>) − log <em>p</em>(<em>y</em><sub><em>j</em></sub>) − log <em>p</em>(<em>y</em><sub><em>j</em></sub>∥<em>y</em><sub><em>k</em></sub>)</span>
Now, the problem we stated above reduces to calculating the entries of
<span class="math display"><em>ω</em>(1)⋯<em>ω</em>(<em>n</em>)</span>
and finding the minimal entry together with the path that produced that
entry.</p>
<h2 id="an-implementation">An implementation</h2>
<p>Let us start with tropic multiplication of matrices. Our matrices
have entries as pairs <code>(path . -log(prob))</code>. Each path at the
entry <code>(i j)</code> is a sequence of indices that starts at <span
class="math inline"><em>i</em></span> and ends at <span
class="math inline"><em>j</em></span>. We are going to concatenate
paths, and tropic multiply entries coming from negative log terms. The
following function takes two matrices of this form and returns their
product.</p>
<pre><code>(defun tropic-mult (a b)
   (let ((n (array-dimension a 0))
         (m (array-dimension b 1))
         (o (array-dimension a 1)))
      (make-array
         (list n m)
         :initial-contents 
            (loop for i from 0 below n collect
               (loop for j from 0 below m collect
                  (car (sort (loop for k from 0 below o collect
                                (cons (append (car (aref a i k))
                                              (cdar (aref b k j)))
                                      (+ (cdr (aref a i k))
                                         (cdr (aref b k j)))))
                       (lambda (x y) (&amp;lt; (cdr x) (cdr y))))))))))
TROPIC-MULT</code></pre>
<h2 id="a-toy-example">A toy example</h2>
<p>Let me test. I will start with something small. Assume I have the
following transition probabilities between two states:</p>
<figure data-orig-width="109" data-orig-height="175">
<img src="../media/2015-07-21-hidden_markov_models_via_tropic_matrices_0.png" data-orig-width="109"
data-orig-height="175" alt="image" />
</figure>
<pre><code>(defvar
   A (make-array
       (list 2 2)
       :initial-contents
         (list (list (cons (list 1 1) (- (log 0.5))) (cons (list 1 2) (- (log 0.5))))
               (list (cons (list 2 1) (- (log 0.4))) (cons (list 2 2) (- (log 0.6)))))))
A
(reduce #’tropic-mult a a a a)
#2A((((1 2 2 2 1) . 2.6310892) ((1 2 2 2 2) . 2.225624))
    (((2 2 2 2 1) . 2.4487674) ((2 2 2 2 2) . 2.0433023)))</code></pre>
<p>The result indicates that the most likely 4-step path is
<code>(2 2 2 2 2)</code> from state 2 to state 2, but if we want we have
the most likely 4-step path from state 1 and state 1 then we
have <code>(1 2 2 2 1)</code></p>
<h2 id="a-real-test">A real test</h2>
<p>For our real test, I am going to need a function that generates the
sequence of matrices we going going to multiply. The following function
takes 3 inputs:</p>
<ol type="1">
<li>A matrix <code>a</code> of the conditional probabilities <span
class="math inline"><em>p</em>(<em>x</em><sub><em>i</em></sub>∥<em>y</em><sub><em>j</em></sub>)</span>
of seeing a state <span
class="math inline"><em>x</em><sub><em>i</em></sub></span> given the
label <span
class="math inline"><em>y</em><sub><em>j</em></sub></span>.</li>
<li>A matrix <code>b</code> of the probability distribution of the
labels <span
class="math inline"><em>y</em><sub><em>j</em></sub></span>’s</li>
<li>A matrix <code>c</code> of transition probabilities <span
class="math inline"><em>p</em>(<em>y</em><sub><em>j</em></sub>∥<em>y</em><sub><em>i</em></sub>)</span>
from a label <span
class="math inline"><em>y</em><sub><em>i</em></sub></span> to another
label <span
class="math inline"><em>y</em><sub><em>j</em></sub></span>.</li>
</ol>
<p>and it returns a list of matrices <span
class="math inline">(<em>ω</em>(1),…,<em>ω</em>(<em>m</em>))</span>.</p>
<pre><code>(defun matrix (a b c)
   (let* ((m (array-dimension a 1))
          (n (array-dimension a 0)))
      (loop for i from 0 below m collect
         (make-array
            (list n n)
            :initial-contents
               (loop for j from 0 below n collect
                  (loop for k from 0 below n collect
                     (cons
                        (list j k)
                        (+ (- (log (aref a j i)))
                           (- (log (aref b j)))
                           (- (log (aref c j k)))))))))))
MATRIX</code></pre>
<p>And our final test:</p>
<pre><code>(let* ((a (make-array
             (list 3 4)
             :initial-contents
               &#39;((0.25 0.25 0.25 0.25)
                 (0.05 0.00 0.95 0.00)
                 (0.40 0.10 0.10 0.40))))
       (b (make-array 3 :initial-contents &#39;(0.5 0.1 0.4)))
       (c (make-array
             (list 3 3)
             :initial-contents
               &#39;((0.75 0.25 0.00)
                 (0.00 0.00 1.00)
                 (0.00 0.00 1.00))))
       (path (mapcar (lambda (x) (position x &#39;(:a :c :g :t)))
                &#39;(:c :t :t :c
                  :a :t :g :t
                  :g :a :a :a
                  :g :c :a :g
                  :a :c :g :t
                  :a :a :g :t
                  :c :a)))
       (matr (matrix a b c)))
   (reduce #&#39;tropic-mult (loop for x in path collect (elt matr x))))
#2A((((0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0) . 61.545197)
     ((0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1) . 62.64381)
     ((0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 2 2 2 2 2 2 2) . 61.66136))
    (((1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0)
      . #.SB-EXT:SINGLE-FLOAT-POSITIVE-INFINITY)
     ((1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1)
      . #.SB-EXT:SINGLE-FLOAT-POSITIVE-INFINITY)
     ((1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2)
      . #.SB-EXT:SINGLE-FLOAT-POSITIVE-INFINITY))
    (((2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0)
      . #.SB-EXT:SINGLE-FLOAT-POSITIVE-INFINITY)
     ((2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1)
      . #.SB-EXT:SINGLE-FLOAT-POSITIVE-INFINITY)
     ((2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2) . 62.896347)))</code></pre>
<p>Now, we see that the most probable path from state 0 to state 2 on
these sequence of observations is
<code>(0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 2 2 2 2 2 2 2)</code>
which agrees with the result obtained in the <a
href="http://www.nature.com/nbt/journal/v22/n10/fig_tab/nbt1004-1315_F1.html">paper</a>
I took this problem from.</p>
<h2 id="an-analysis">An analysis</h2>
<p>Comparing the results with <a
href="clean/2015-06-28-an_implementation_of_the_viterbi_algorithm_in_common_lisp.html">my
previous post</a>, we see that recursion with no memory leads to the
most probable path with a given initial state, while in today’s
implementation we find the most probable path with the chosen initial
and terminal state which is more desirable.</p>
<div id="footer">
<p><span id="timestamp">July 21st, 2015 7:17am</span></p>
</div>
</body>
</html>
