<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>2015-07-21-hidden_markov_models_via_tropic_matrices</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="style.css" />
  <html>
  <meta http-equiv="content-type" content="text/html; charset=UTF-8">
  <base href="https://kaygun.github.io/">
  <link rel="stylesheet" type="text/css" href="style.css">


  <head>
  <title>The Kitchen Sink and Other Oddities</title>
  </head>

  <body>
  <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ['\\(','\\)'] ]
    }
  });
  </script>

  <div class="header">
  <h1><a href="https://kaygun.github.io">The Kitchen Sink and Other Oddities</a></h1>
  <p><a href="https://web.itu.edu.tr/kaygun">Atabey Kaygun</a></p>
  </div>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<h1 id="hidden-markov-models-via-tropic-matrices">Hidden Markov Models
via Tropic Matrices</h1>
<p>I covered some of the material in <a
href="clean/2015-06-28-an_implementation_of_the_viterbi_algorithm_in_common_lisp.html">my
previous post</a>, but let me repeat it anyway.</p>
<h2 id="description-of-the-problem">Description of the problem</h2>
<p>We have an ordered sequence of observations <span
class="math inline">\(x_1,x_2,\ldots,x_N\)</span> where each observation
is labeled from a finite set of classes <span
class="math inline">\(Y\)</span>. The probability that an observation
<span class="math inline">\(x\)</span> is labeled as <span
class="math inline">\(y\in Y\)</span> is given by <span
class="math inline">\(p(y\|x)\)</span>. We assume that we know the
probability distributions for the observations <span
class="math inline">\(p(x)\)</span> and classes <span
class="math inline">\(p(y)\)</span>, and the probability <span
class="math inline">\(p(x\|y)\)</span> of seeing the observation <span
class="math inline">\(x\)</span> under the label <span
class="math inline">\(y\)</span>. Assume also that we have transition
probabilities <span class="math inline">\(p(y&#39;\|y)\)</span> telling
us the probability of seeing class label <span
class="math inline">\(y&#39;\in Y\)</span> right after observing <span
class="math inline">\(y\in Y\)</span>.</p>
<p>Our task is to find the labeling scheme <span
class="math inline">\(\ell\colon \{x_1,\ldots,x_N\}\to Y\)</span> of the
observations with the maximum likelihood. In other words, we need to
maximize <span class="math display">\[ \pi(\ell) =
\prod_{i=1}^N p(\ell(x_i)\|x_i)p(\ell(x_{i+1})\|\ell(x_i)) \]</span> We
set <span class="math inline">\(p(\ell(x_{N+1})\|\ell(x_N))=1\)</span>
to make the product meaningful.</p>
<h2 id="a-reduction">A reduction</h2>
<p>Taking the logarithms and expanding we get <span
class="math display">\[ \log\pi(\ell) =
\sum_{i=1}^N \log p(\ell(x_i)\| x_i) + \sum_{i=1}^{N-1} \log
p(\ell(x_{i+1})\|\ell(x_i)) \]</span> which then can be simplified as
<span class="math display">\[
= \sum_{i=1}^N \log p(\ell(x_{i+1})\|\ell(x_i)) + \sum_{i=1}^N
\log p(x_i\|\ell(x_i)) + \log p(\ell(x_i)) - \log p(x_i) \]</span>
Notice that we can drop <span class="math inline">\(\log p(x_i)\)</span>
terms since they do not depend on <span
class="math inline">\(\ell\)</span>. Since logarithms of probabilities
lie in <span class="math inline">\((-\infty,0\]\)</span>, we need to
minimize the quantity below: <span class="math display">\[
-\log\pi(\ell) \sim \tau(\ell) := \sum_{i=1}^N -\log
p(\ell(x_{i+1})\|\ell(x_i)) + \sum_{i=1}^N -\log
p(x_i\|\ell(x_i)) + \sum_{i=1}^N -\log p(\ell(x_i)) \]</span> Let us
rearrange the terms a bit: <span class="math display">\[ \tau(\ell) = -
\sum_{i=1}^N \log
p(x_i\|\ell(x_i)) + \log p(\ell(x_i)) + \log
p(\ell(x_i)\|\ell(x_{i-1})) \]</span> by letting <span
class="math inline">\(p(\ell(x_1)\|\ell(x_0))=1\)</span> in the
equation.</p>
<h2 id="tropic-semiring">Tropic semiring</h2>
<p>We consider the set of non-negative real numbers <span
class="math inline">\(\mathbb{R}_+ := \[0,\infty)\)</span> together with
the operations <span class="math inline">\(\min\)</span> (which we
denote as <span class="math inline">\(\min(x,y) = x\wedge y\)</span>)
and ordinary product. Notice that <span class="math display">\[
x + (y\wedge z) = (x+y)\wedge(x+z) \]</span> However, <span
class="math inline">\(\wedge\)</span> does not have a unit and <span
class="math inline">\(0\wedge x = x\wedge 0 = 0\)</span>.</p>
<p>One can form matrices in the tropic semi-rng. Assume we have two such
tropic matrices <span class="math inline">\(A_{n\times m} =
(a_{ij})\)</span> and <span class="math inline">\(B_{m\times\ell} =
(b_{ij})\)</span> then the product <span
class="math inline">\(C_{n\times\ell} = A\ast B\)</span> has the entries
<span class="math display">\[ c_{ij} = \bigwedge_{k=1}^m (a_{ik} +
b_{kj}) \]</span></p>
<h2 id="re-imagining-our-problem-in-tropic-terms">Re-imagining our
problem in tropic terms</h2>
<p>Let us define matrices <span class="math inline">\(\omega_i\)</span>
for <span class="math inline">\(i=1,\ldots,n\)</span> as <span
class="math display">\[
\omega_{jk}(i) = - \log p(x_i\|y_j) - \log p(y_j) - \log
p(y_j\|y_k) \]</span> Now, the problem we stated above reduces to
calculating the entries of <span class="math display">\[
\omega(1)\cdots\omega(n) \]</span> and finding the minimal entry
together with the path that produced that entry.</p>
<h2 id="an-implementation">An implementation</h2>
<p>Let us start with tropic multiplication of matrices. Our matrices
have entries as pairs <code>(path . -log(prob))</code>. Each path at the
entry <code>(i j)</code> is a sequence of indices that starts at <span
class="math inline">\(i\)</span> and ends at <span
class="math inline">\(j\)</span>. We are going to concatenate paths, and
tropic multiply entries coming from negative log terms. The following
function takes two matrices of this form and returns their product.</p>
<pre><code>(defun tropic-mult (a b)
   (let ((n (array-dimension a 0))
         (m (array-dimension b 1))
         (o (array-dimension a 1)))
      (make-array
         (list n m)
         :initial-contents 
            (loop for i from 0 below n collect
               (loop for j from 0 below m collect
                  (car (sort (loop for k from 0 below o collect
                                (cons (append (car (aref a i k))
                                              (cdar (aref b k j)))
                                      (+ (cdr (aref a i k))
                                         (cdr (aref b k j)))))
                       (lambda (x y) (&amp;lt; (cdr x) (cdr y))))))))))
TROPIC-MULT</code></pre>
<h2 id="a-toy-example">A toy example</h2>
<p>Let me test. I will start with something small. Assume I have the
following transition probabilities between two states:</p>
<figure data-orig-width="109" data-orig-height="175">
<img src="../media/2015-07-21-hidden_markov_models_via_tropic_matrices_0.png" data-orig-width="109"
data-orig-height="175" alt="image" />
</figure>
<pre><code>(defvar
   A (make-array
       (list 2 2)
       :initial-contents
         (list (list (cons (list 1 1) (- (log 0.5))) (cons (list 1 2) (- (log 0.5))))
               (list (cons (list 2 1) (- (log 0.4))) (cons (list 2 2) (- (log 0.6)))))))
A
(reduce #’tropic-mult a a a a)
#2A((((1 2 2 2 1) . 2.6310892) ((1 2 2 2 2) . 2.225624))
    (((2 2 2 2 1) . 2.4487674) ((2 2 2 2 2) . 2.0433023)))</code></pre>
<p>The result indicates that the most likely 4-step path is
<code>(2 2 2 2 2)</code> from state 2 to state 2, but if we want we have
the most likely 4-step path from state 1 and state 1 then we
have <code>(1 2 2 2 1)</code></p>
<h2 id="a-real-test">A real test</h2>
<p>For our real test, I am going to need a function that generates the
sequence of matrices we going going to multiply. The following function
takes 3 inputs:</p>
<ol type="1">
<li>A matrix <code>a</code> of the conditional probabilities <span
class="math inline">\(p(x_i\|y_j)\)</span> of seeing a state <span
class="math inline">\(x_i\)</span> given the label <span
class="math inline">\(y_j\)</span>.</li>
<li>A matrix <code>b</code> of the probability distribution of the
labels <span class="math inline">\(y_j\)</span>’s</li>
<li>A matrix <code>c</code> of transition probabilities <span
class="math inline">\(p(y_j\|y_i)\)</span> from a label <span
class="math inline">\(y_i\)</span> to another label <span
class="math inline">\(y_j\)</span>.</li>
</ol>
<p>and it returns a list of matrices <span
class="math inline">\((\omega(1),\ldots,\omega(m))\)</span>.</p>
<pre><code>(defun matrix (a b c)
   (let* ((m (array-dimension a 1))
          (n (array-dimension a 0)))
      (loop for i from 0 below m collect
         (make-array
            (list n n)
            :initial-contents
               (loop for j from 0 below n collect
                  (loop for k from 0 below n collect
                     (cons
                        (list j k)
                        (+ (- (log (aref a j i)))
                           (- (log (aref b j)))
                           (- (log (aref c j k)))))))))))
MATRIX</code></pre>
<p>And our final test:</p>
<pre><code>(let* ((a (make-array
             (list 3 4)
             :initial-contents
               &#39;((0.25 0.25 0.25 0.25)
                 (0.05 0.00 0.95 0.00)
                 (0.40 0.10 0.10 0.40))))
       (b (make-array 3 :initial-contents &#39;(0.5 0.1 0.4)))
       (c (make-array
             (list 3 3)
             :initial-contents
               &#39;((0.75 0.25 0.00)
                 (0.00 0.00 1.00)
                 (0.00 0.00 1.00))))
       (path (mapcar (lambda (x) (position x &#39;(:a :c :g :t)))
                &#39;(:c :t :t :c
                  :a :t :g :t
                  :g :a :a :a
                  :g :c :a :g
                  :a :c :g :t
                  :a :a :g :t
                  :c :a)))
       (matr (matrix a b c)))
   (reduce #&#39;tropic-mult (loop for x in path collect (elt matr x))))
#2A((((0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0) . 61.545197)
     ((0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1) . 62.64381)
     ((0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 2 2 2 2 2 2 2) . 61.66136))
    (((1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0)
      . #.SB-EXT:SINGLE-FLOAT-POSITIVE-INFINITY)
     ((1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1)
      . #.SB-EXT:SINGLE-FLOAT-POSITIVE-INFINITY)
     ((1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2)
      . #.SB-EXT:SINGLE-FLOAT-POSITIVE-INFINITY))
    (((2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0)
      . #.SB-EXT:SINGLE-FLOAT-POSITIVE-INFINITY)
     ((2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1)
      . #.SB-EXT:SINGLE-FLOAT-POSITIVE-INFINITY)
     ((2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2) . 62.896347)))</code></pre>
<p>Now, we see that the most probable path from state 0 to state 2 on
these sequence of observations is
<code>(0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 2 2 2 2 2 2 2)</code>
which agrees with the result obtained in the <a
href="http://www.nature.com/nbt/journal/v22/n10/fig_tab/nbt1004-1315_F1.html">paper</a>
I took this problem from.</p>
<h2 id="an-analysis">An analysis</h2>
<p>Comparing the results with <a
href="clean/2015-06-28-an_implementation_of_the_viterbi_algorithm_in_common_lisp.html">my
previous post</a>, we see that recursion with no memory leads to the
most probable path with a given initial state, while in today’s
implementation we find the most probable path with the chosen initial
and terminal state which is more desirable.</p>
<div id="footer">
<p><span id="timestamp">July 21st, 2015 7:17am</span></p>
</div>
</body>
</html>
